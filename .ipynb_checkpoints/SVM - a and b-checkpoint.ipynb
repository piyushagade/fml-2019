{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6264\n",
      "6264\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from plotcm import plot_confusion_matrix\n",
    "\n",
    "import pdb\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "\n",
    "import pickle\n",
    "def load_pkl(fname):\n",
    "    with open(fname,'rb') as f:\n",
    "        return pickle.load(f)\n",
    "def save_pkl(fname,obj):\n",
    "    with open(fname,'wb') as f:\n",
    "        pickle.dump(obj,f)\n",
    "\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "data = np.load('balanced_data.npy', allow_pickle=True)\n",
    "label = np.load('balanced_labels.npy', allow_pickle=True)\n",
    "\n",
    "print(len(data))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision is the fraction of relevant instances among the retrieved instances and is defined as:\n",
    "\n",
    "# precision = tp / (tp + fp) or (true positives)/(prediced positives)\n",
    "\n",
    "# recall is the fraction of relevant instances that have been retrieved over total relevant instances in the image, and is defined as\n",
    "\n",
    "# recall = tp / (tp + fn) or (true positives)/(actual positives)\n",
    "\n",
    "# Where, tp = true positives, fp = false positives anf fn = false negatives. Recall in this context is also referred to as the true positive rate or sensitivity, and precision is also referred to as positive predictive value (PPV).\n",
    "\n",
    "# f1-score: is a measure of a test's accuracy. It considers both the precision and the recall to compute the score. The f1-score can be interpreted as a weighted average of the precision and recall, where an f1-score reaches its best value at 1 and worst at 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data =[]\n",
    "new_label = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (label[i] == 1 or label[i] == 2):\n",
    "        new_data.append(data[i])\n",
    "        new_label.append(label[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while (i < len(new_data)):\n",
    "    #data[i] = resize(data[i], (50,50))\n",
    "    new_data[i] = np.array(new_data[i]).astype(float)\n",
    "    result = np.zeros((54,54), dtype =float)\n",
    "    result[:new_data[i].shape[0],:new_data[i].shape[1]] = new_data[i]\n",
    "    new_data[i] = result\n",
    "    i += 1\n",
    "new_label = [i-1 for i in new_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data and target sizes: \n",
      "(1409, 2916), (1409,)\n",
      "Test data and target sizes: \n",
      "(157, 2916), (157,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(new_data).reshape((1566,54*54)).astype(int),np.array(new_label).astype(int), test_size=0.1, random_state=42)\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1566, 2916)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(new_data).reshape((1566,54*54)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "#fit to the trainin data\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "# now to Now predict the value of the digit on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        77\n",
      "           1       0.98      0.99      0.98        80\n",
      "\n",
      "    accuracy                           0.98       157\n",
      "   macro avg       0.98      0.98      0.98       157\n",
      "weighted avg       0.98      0.98      0.98       157\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#=============================Without Standard Scalaing====================================\n",
    "#prev\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[75  2]\n",
      " [ 1 79]]\n"
     ]
    }
   ],
   "source": [
    "#==============================Without Standard Scalaing==================================\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        77\n",
      "           1       1.00      0.96      0.98        80\n",
      "\n",
      "    accuracy                           0.98       157\n",
      "   macro avg       0.98      0.98      0.98       157\n",
      "weighted avg       0.98      0.98      0.98       157\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[77  0]\n",
      " [ 3 77]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
